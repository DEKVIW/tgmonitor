#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨é“¾æ¥æœ‰æ•ˆæ€§æ£€æµ‹æ¨¡å—
æ”¯æŒå¤šç§æ£€æµ‹æ–¹å¼å’Œç½‘ç›˜ç‰¹æ®Šå¤„ç†
"""

import asyncio
import aiohttp
import re
import time
import random
from typing import Dict, List, Tuple, Optional
from urllib.parse import urlparse
import validators

class LinkValidator:
    """é“¾æ¥æœ‰æ•ˆæ€§æ£€æµ‹å™¨"""
    
    def __init__(self):
        # ç½‘ç›˜ç‰¹å®šçš„å¤±æ•ˆå…³é”®è¯
        self.netdisk_invalid_patterns = {
            "ç™¾åº¦ç½‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"åˆ†äº«é“¾æ¥å·²å¤±æ•ˆ",
                r"æ–‡ä»¶å·²è¢«åˆ é™¤", r"åˆ†äº«å·²å–æ¶ˆ", r"è®¿é—®è¢«æ‹’ç»"
            ],
            "å¤¸å…‹ç½‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤", r"åˆ†äº«é“¾æ¥å·²å¤±æ•ˆ", r"æ–‡ä»¶å·²è¢«åˆ é™¤",
                r"åˆ†äº«å·²è¿‡æœŸ", r"è®¿é—®è¢«æ‹’ç»"
            ],
            "é˜¿é‡Œäº‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ],
            "115ç½‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ],
            "å¤©ç¿¼äº‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ],
            "123äº‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ],
            "UCç½‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ],
            "è¿…é›·ç½‘ç›˜": [
                r"æ–‡ä»¶ä¸å­˜åœ¨", r"åˆ†äº«å·²å¤±æ•ˆ", r"é“¾æ¥å·²è¿‡æœŸ", r"æ–‡ä»¶å·²è¢«åˆ é™¤"
            ]
        }
        
        # é€šç”¨å¤±æ•ˆå…³é”®è¯
        self.general_invalid_patterns = [
            r"é¡µé¢ä¸å­˜åœ¨", r"è®¿é—®è¢«æ‹’ç»", r"æœåŠ¡å™¨é”™è¯¯",
            r"é¡µé¢æœªæ‰¾åˆ°", r"æ— æ³•è®¿é—®", r"è¿æ¥è¶…æ—¶",
            r"404\s*é”™è¯¯", r"404\s*é¡µé¢", r"404\s*not\s*found"
        ]
        
        # ç½‘ç›˜ç‰¹å®šçš„è¯·æ±‚é™åˆ¶
        self.netdisk_limits = {
            "ç™¾åº¦ç½‘ç›˜": {"max_concurrent": 3, "delay_range": (1, 3)},
            "å¤¸å…‹ç½‘ç›˜": {"max_concurrent": 5, "delay_range": (0.5, 2)},
            "é˜¿é‡Œäº‘ç›˜": {"max_concurrent": 4, "delay_range": (1, 2.5)},
            "115ç½‘ç›˜": {"max_concurrent": 2, "delay_range": (2, 4)},
            "å¤©ç¿¼äº‘ç›˜": {"max_concurrent": 3, "delay_range": (1, 3)},
            "123äº‘ç›˜": {"max_concurrent": 3, "delay_range": (1, 2)},
            "UCç½‘ç›˜": {"max_concurrent": 3, "delay_range": (1, 2)},
            "è¿…é›·ç½‘ç›˜": {"max_concurrent": 3, "delay_range": (1, 2)},
            "æœªçŸ¥ç½‘ç›˜": {"max_concurrent": 2, "delay_range": (2, 4)}
        }
        
        # è¯·æ±‚å¤´ - æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',  # ç§»é™¤brç¼–ç ï¼Œé¿å…Brotlié—®é¢˜
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
        }
        
        # é”™è¯¯è®¡æ•°å’Œé™åˆ¶
        self.error_counts = {}
        self.max_errors_per_netdisk = 10  # æ¯ä¸ªç½‘ç›˜æœ€å¤šå…è®¸10ä¸ªè¿ç»­é”™è¯¯
        
        # é‡è¯•æœºåˆ¶é…ç½®
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 2  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        
        # å¯é‡è¯•çš„é”™è¯¯ç±»å‹
        self.retryable_errors = [
            'ç½‘ç»œè¶…æ—¶', 'ç½‘ç»œé”™è¯¯', 'çŠ¶æ€ç é”™è¯¯', 'æ£€æµ‹å¼‚å¸¸'
        ]
        
        # ä¸å¯é‡è¯•çš„é”™è¯¯ç±»å‹
        self.non_retryable_errors = [
            'æ ¼å¼é”™è¯¯', 'ç½‘ç›˜é“¾æ¥å¤±æ•ˆ', 'é¡µé¢é”™è¯¯', 'ç½‘ç›˜é™åˆ¶'
        ]
    
    def validate_url_format(self, url: str) -> bool:
        """å¿«é€ŸéªŒè¯URLæ ¼å¼"""
        try:
            parsed = urlparse(url)
            # æ£€æŸ¥åŸºæœ¬æ ¼å¼ï¼šå¿…é¡»æœ‰schemeå’Œnetloc
            return bool(parsed.scheme and parsed.netloc and 
                       parsed.scheme in ('http', 'https'))
        except Exception:
            return False
    
    def get_netdisk_type(self, url: str) -> str:
        """æ ¹æ®URLåˆ¤æ–­ç½‘ç›˜ç±»å‹"""
        domain = urlparse(url).netloc.lower()
        
        netdisk_domains = {
            "ç™¾åº¦ç½‘ç›˜": ["pan.baidu.com"],
            "å¤¸å…‹ç½‘ç›˜": ["pan.quark.cn"],
            "é˜¿é‡Œäº‘ç›˜": ["www.alipan.com", "www.aliyundrive.com"],
            "115ç½‘ç›˜": ["115.com", "115cdn.com"],
            "å¤©ç¿¼äº‘ç›˜": ["cloud.189.cn"],
            "123äº‘ç›˜": ["www.123684.com", "www.123pan.com"],
            "UCç½‘ç›˜": ["drive.uc.cn"],
            "è¿…é›·ç½‘ç›˜": ["pan.xunlei.com"]
        }
        
        for netdisk, domains in netdisk_domains.items():
            if any(domain in d for d in domains):
                return netdisk
        
        return "æœªçŸ¥ç½‘ç›˜"
    
    def get_netdisk_limits(self, netdisk_type: str) -> Dict:
        """è·å–ç½‘ç›˜ç‰¹å®šçš„é™åˆ¶é…ç½®"""
        return self.netdisk_limits.get(netdisk_type, self.netdisk_limits["æœªçŸ¥ç½‘ç›˜"])
    
    async def check_single_link(self, url: str, timeout: int = 15) -> Dict:
        """æ£€æµ‹å•ä¸ªé“¾æ¥çš„æœ‰æ•ˆæ€§"""
        result = {
            'url': url,
            'netdisk_type': self.get_netdisk_type(url),
            'is_valid': False,
            'status_code': None,
            'response_time': None,
            'error': None,
            'reason': None
        }
        
        netdisk_type = result['netdisk_type']
        
        # æ£€æŸ¥é”™è¯¯è®¡æ•°
        if self.error_counts.get(netdisk_type, 0) >= self.max_errors_per_netdisk:
            result['error'] = f"ç½‘ç›˜ {netdisk_type} é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œæš‚åœæ£€æµ‹"
            result['reason'] = "ç½‘ç›˜é™åˆ¶"
            return result
        
        # é¦–å…ˆéªŒè¯URLæ ¼å¼
        try:
            parsed = urlparse(url)
            if not (parsed.scheme and parsed.netloc and parsed.scheme in ('http', 'https')):
                result['error'] = "URLæ ¼å¼æ— æ•ˆ"
                result['reason'] = "æ ¼å¼é”™è¯¯"
                return result
        except Exception:
            result['error'] = "URLæ ¼å¼æ— æ•ˆ"
            result['reason'] = "æ ¼å¼é”™è¯¯"
            return result
        
        # æ·»åŠ éšæœºå»¶è¿Ÿ
        limits = self.get_netdisk_limits(netdisk_type)
        delay = random.uniform(*limits['delay_range'])
        await asyncio.sleep(delay)
        
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url, 
                    headers=self.headers, 
                    timeout=aiohttp.ClientTimeout(total=timeout),
                    allow_redirects=True
                ) as response:
                    result['response_time'] = time.time() - start_time
                    result['status_code'] = response.status
                    
                    # æ£€æŸ¥HTTPçŠ¶æ€ç 
                    if response.status != 200:
                        result['error'] = f"HTTP {response.status}"
                        result['reason'] = "çŠ¶æ€ç é”™è¯¯"
                        # å¢åŠ é”™è¯¯è®¡æ•°
                        self.error_counts[netdisk_type] = self.error_counts.get(netdisk_type, 0) + 1
                        return result
                    
                    # è·å–é¡µé¢å†…å®¹
                    content = await response.text()
                    
                    # æ£€æŸ¥ç½‘ç›˜ç‰¹å®šçš„å¤±æ•ˆæ¨¡å¼
                    if netdisk_type in self.netdisk_invalid_patterns:
                        patterns = self.netdisk_invalid_patterns[netdisk_type]
                        for pattern in patterns:
                            if re.search(pattern, content, re.IGNORECASE):
                                result['error'] = f"ç½‘ç›˜æ˜¾ç¤ºå¤±æ•ˆ: {pattern}"
                                result['reason'] = "ç½‘ç›˜é“¾æ¥å¤±æ•ˆ"
                                return result
                    
                    # æ£€æŸ¥é€šç”¨å¤±æ•ˆæ¨¡å¼
                    for pattern in self.general_invalid_patterns:
                        if re.search(pattern, content, re.IGNORECASE):
                            result['error'] = f"é¡µé¢æ˜¾ç¤ºé”™è¯¯: {pattern}"
                            result['reason'] = "é¡µé¢é”™è¯¯"
                            return result
                    
                    # å¦‚æœé€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼Œè®¤ä¸ºé“¾æ¥æœ‰æ•ˆ
                    result['is_valid'] = True
                    result['reason'] = "é“¾æ¥æœ‰æ•ˆ"
                    # é‡ç½®é”™è¯¯è®¡æ•°
                    self.error_counts[netdisk_type] = 0
                    
        except asyncio.TimeoutError:
            result['error'] = "è¯·æ±‚è¶…æ—¶"
            result['reason'] = "ç½‘ç»œè¶…æ—¶"
            self.error_counts[netdisk_type] = self.error_counts.get(netdisk_type, 0) + 1
        except aiohttp.ClientError as e:
            result['error'] = f"ç½‘ç»œé”™è¯¯: {str(e)}"
            result['reason'] = "ç½‘ç»œé”™è¯¯"
            self.error_counts[netdisk_type] = self.error_counts.get(netdisk_type, 0) + 1
        except Exception as e:
            result['error'] = f"æœªçŸ¥é”™è¯¯: {str(e)}"
            result['reason'] = "æœªçŸ¥é”™è¯¯"
            self.error_counts[netdisk_type] = self.error_counts.get(netdisk_type, 0) + 1
        
        return result
    
    def is_retryable_error(self, result: Dict) -> bool:
        """åˆ¤æ–­é”™è¯¯æ˜¯å¦å¯é‡è¯•"""
        return result.get('reason') in self.retryable_errors
    
    async def retry_failed_links(self, failed_results: List[Dict]) -> List[Dict]:
        """é‡è¯•å¤±è´¥çš„é“¾æ¥"""
        if not failed_results:
            return []
        
        retryable_results = [r for r in failed_results if self.is_retryable_error(r)]
        if not retryable_results:
            return failed_results
        
        print(f"ğŸ”„ å¼€å§‹é‡è¯• {len(retryable_results)} ä¸ªå¯é‡è¯•çš„é“¾æ¥...")
        
        # æŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„é‡è¯•
        netdisk_groups = {}
        for result in retryable_results:
            netdisk_type = result['netdisk_type']
            if netdisk_type not in netdisk_groups:
                netdisk_groups[netdisk_type] = []
            netdisk_groups[netdisk_type].append(result['url'])
        
        retry_results = []
        
        for netdisk_type, urls in netdisk_groups.items():
            print(f"ğŸ”„ é‡è¯• {netdisk_type}: {len(urls)} ä¸ªé“¾æ¥")
            
            # é‡è¯•æ¯ä¸ªé“¾æ¥
            for url in urls:
                for attempt in range(1, self.max_retries + 1):
                    print(f"  ğŸ”„ é‡è¯• {url} (ç¬¬{attempt}æ¬¡)")
                    
                    # é‡è¯•å‰ç­‰å¾…
                    await asyncio.sleep(self.retry_delay)
                    
                    # é‡æ–°æ£€æµ‹
                    new_result = await self.check_single_link(url)
                    
                    # å¦‚æœæˆåŠŸæˆ–ä¸å¯é‡è¯•ï¼Œåœæ­¢é‡è¯•
                    if new_result['is_valid'] or not self.is_retryable_error(new_result):
                        retry_results.append(new_result)
                        break
                    
                    # æœ€åä¸€æ¬¡é‡è¯•
                    if attempt == self.max_retries:
                        retry_results.append(new_result)
                        print(f"    âŒ é‡è¯•{self.max_retries}æ¬¡åä»ç„¶å¤±è´¥")
        
        # åˆå¹¶ç»“æœï¼šé‡è¯•æˆåŠŸçš„æ›¿æ¢åŸç»“æœï¼Œé‡è¯•å¤±è´¥çš„ä¿æŒåŸç»“æœ
        final_results = []
        retry_urls = {r['url'] for r in retry_results}
        
        for result in failed_results:
            if result['url'] in retry_urls:
                # æ‰¾åˆ°é‡è¯•ç»“æœ
                retry_result = next(r for r in retry_results if r['url'] == result['url'])
                final_results.append(retry_result)
            else:
                # ä¸å¯é‡è¯•çš„é”™è¯¯ï¼Œä¿æŒåŸç»“æœ
                final_results.append(result)
        
        return final_results

    async def check_multiple_links(self, urls: List[str], max_concurrent: int = 5) -> List[Dict]:
        """å¹¶å‘æ£€æµ‹å¤šä¸ªé“¾æ¥ - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ”¯æŒé‡è¯•"""
        # æŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„
        netdisk_groups = {}
        for url in urls:
            netdisk_type = self.get_netdisk_type(url)
            if netdisk_type not in netdisk_groups:
                netdisk_groups[netdisk_type] = []
            netdisk_groups[netdisk_type].append(url)
        
        print(f"ğŸ“Š æŒ‰ç½‘ç›˜ç±»å‹åˆ†ç»„: {len(netdisk_groups)} ç§ç½‘ç›˜")
        for netdisk, urls_list in netdisk_groups.items():
            limits = self.get_netdisk_limits(netdisk)
            print(f"  - {netdisk}: {len(urls_list)} ä¸ªé“¾æ¥, æœ€å¤§å¹¶å‘ {limits['max_concurrent']}, å»¶è¿Ÿ {limits['delay_range']}ç§’")
        
        all_results = []
        
        # æŒ‰ç½‘ç›˜ç±»å‹åˆ†åˆ«å¤„ç†
        for netdisk_type, netdisk_urls in netdisk_groups.items():
            limits = self.get_netdisk_limits(netdisk_type)
            netdisk_concurrent = min(limits['max_concurrent'], max_concurrent)
            
            print(f"ğŸ” å¼€å§‹æ£€æµ‹ {netdisk_type} ({len(netdisk_urls)} ä¸ªé“¾æ¥, å¹¶å‘ {netdisk_concurrent})")
            
            # ä¸ºæ¯ä¸ªç½‘ç›˜åˆ›å»ºä¿¡å·é‡
            semaphore = asyncio.Semaphore(netdisk_concurrent)
            
            async def check_with_semaphore(url):
                async with semaphore:
                    return await self.check_single_link(url)
            
            # æ£€æµ‹å½“å‰ç½‘ç›˜çš„é“¾æ¥
            tasks = [check_with_semaphore(url) for url in netdisk_urls]
            netdisk_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            for i, result in enumerate(netdisk_results):
                if isinstance(result, Exception):
                    netdisk_results[i] = {
                        'url': netdisk_urls[i],
                        'netdisk_type': netdisk_type,
                        'is_valid': False,
                        'status_code': None,
                        'response_time': None,
                        'error': str(result),
                        'reason': "æ£€æµ‹å¼‚å¸¸"
                    }
            
            all_results.extend(netdisk_results)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é”™è¯¯é™åˆ¶
            if self.error_counts.get(netdisk_type, 0) >= self.max_errors_per_netdisk:
                print(f"âš ï¸  {netdisk_type} é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œè·³è¿‡å‰©ä½™é“¾æ¥")
                # ä¸ºå‰©ä½™é“¾æ¥æ·»åŠ è·³è¿‡æ ‡è®°
                remaining_count = len(netdisk_urls) - len(netdisk_results)
                for _ in range(remaining_count):
                    all_results.append({
                        'url': 'skipped',
                        'netdisk_type': netdisk_type,
                        'is_valid': False,
                        'status_code': None,
                        'response_time': None,
                        'error': f"{netdisk_type} é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œè·³è¿‡æ£€æµ‹",
                        'reason': "ç½‘ç›˜é™åˆ¶"
                    })
        
        # ç¬¬ä¸€è½®æ£€æµ‹å®Œæˆï¼Œå¼€å§‹é‡è¯•å¤±è´¥çš„é“¾æ¥
        failed_results = [r for r in all_results if not r['is_valid']]
        if failed_results:
            print(f"\nğŸ“Š ç¬¬ä¸€è½®æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(failed_results)} ä¸ªå¤±è´¥é“¾æ¥")
            
            # é‡è¯•å¤±è´¥çš„é“¾æ¥
            retry_results = await self.retry_failed_links(failed_results)
            
            # æ›´æ–°ç»“æœ
            final_results = []
            failed_urls = {r['url'] for r in failed_results}
            
            for result in all_results:
                if result['url'] in failed_urls:
                    # æ‰¾åˆ°é‡è¯•ç»“æœ
                    retry_result = next(r for r in retry_results if r['url'] == result['url'])
                    final_results.append(retry_result)
                else:
                    # æˆåŠŸçš„é“¾æ¥ï¼Œä¿æŒåŸç»“æœ
                    final_results.append(result)
            
            return final_results
        
        return all_results
    
    def get_summary(self, results: List[Dict]) -> Dict:
        """è·å–æ£€æµ‹ç»“æœæ‘˜è¦"""
        total = len(results)
        valid = sum(1 for r in results if r['is_valid'])
        invalid = total - valid
        
        # æŒ‰ç½‘ç›˜ç±»å‹ç»Ÿè®¡
        netdisk_stats = {}
        for result in results:
            netdisk = result['netdisk_type']
            if netdisk not in netdisk_stats:
                netdisk_stats[netdisk] = {'total': 0, 'valid': 0, 'invalid': 0}
            
            netdisk_stats[netdisk]['total'] += 1
            if result['is_valid']:
                netdisk_stats[netdisk]['valid'] += 1
            else:
                netdisk_stats[netdisk]['invalid'] += 1
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        response_times = [r['response_time'] for r in results if r['response_time'] is not None]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        return {
            'total_links': total,
            'valid_links': valid,
            'invalid_links': invalid,
            'success_rate': (valid / total * 100) if total > 0 else 0,
            'avg_response_time': avg_response_time,
            'netdisk_stats': netdisk_stats
        }

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""
    validator = LinkValidator()
    
    # æµ‹è¯•é“¾æ¥
    test_urls = [
        "https://pan.quark.cn/s/1035a75ca667#/list/share",
        "https://pan.baidu.com/share/init?surl=kq2X2n1Yn_to_ZS41qYJFw&pwd=t6ic",
        "https://www.alipan.com/s/q2QX6AGdJm5"
    ]
    
    print("å¼€å§‹æ£€æµ‹é“¾æ¥...")
    results = await validator.check_multiple_links(test_urls)
    
    # æ‰“å°ç»“æœ
    for result in results:
        status = "âœ…" if result['is_valid'] else "âŒ"
        print(f"{status} {result['netdisk_type']}: {result['url']}")
        print(f"   çŠ¶æ€: {result['reason']}")
        if result['response_time']:
            print(f"   å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
        if result['error']:
            print(f"   é”™è¯¯: {result['error']}")
        print()
    
    # æ‰“å°æ‘˜è¦
    summary = validator.get_summary(results)
    print(f"æ£€æµ‹å®Œæˆ: {summary['valid_links']}/{summary['total_links']} ä¸ªé“¾æ¥æœ‰æ•ˆ")
    print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
    print(f"å¹³å‡å“åº”æ—¶é—´: {summary['avg_response_time']:.2f}ç§’")

if __name__ == "__main__":
    asyncio.run(main()) 